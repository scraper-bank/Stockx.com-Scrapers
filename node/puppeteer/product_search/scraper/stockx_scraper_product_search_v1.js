/**
 * Generated by: ScrapeOps AI Scraper Generator on 2026-02-17
 * Signup For Free Beta: https://scrapeops.io/app/register/ai-scraper-generator
 * Docs & Updates: https://scrapeops.io/docs/ai-scraper-generator
 * For Support & Feedback Email: ai-scraper-generator@scrapeops.io
 */

const puppeteer = require('puppeteer-extra');
const StealthPlugin = require('puppeteer-extra-plugin-stealth');
const cheerio = require('cheerio');
const fs = require('fs');
const { promisify } = require('util');

// Add stealth plugin
puppeteer.use(StealthPlugin());

const API_KEY = 'YOUR-API_KEY';

/**
 * Generate output filename with current timestamp
 * @returns {string} Output filename
 */
function generateOutputFilename() {
    const now = new Date();
    const timestamp = now.getFullYear().toString() +
        (now.getMonth() + 1).toString().padStart(2, '0') +
        now.getDate().toString().padStart(2, '0') + '_' +
        now.getHours().toString().padStart(2, '0') +
        now.getMinutes().toString().padStart(2, '0') +
        now.getSeconds().toString().padStart(2, '0');
    return 'stockx_com_product_search_page_scraper_data_' + timestamp + '.jsonl';
}

// ScrapeOps Residential Proxy Configuration
const PROXY_SERVER = 'residential-proxy.scrapeops.io';
const PROXY_PORT = '8181';
const PROXY_USERNAME = 'scrapeops';
const PROXY_PASSWORD = API_KEY;

// Configuration
const CONFIG = {
    maxRetries: 3,
    maxConcurrency: 1,
    timeout: 180000,
    outputFile: generateOutputFilename()
};

/**
 * Data pipeline for handling scraped data
 */
class DataPipeline {
    constructor(outputFile = CONFIG.outputFile) {
        this.itemsSeen = new Set();
        this.outputFile = outputFile;
        this.writeFile = promisify(fs.appendFile);
    }

    isDuplicate(data) {
        const itemKey = JSON.stringify(data);
        if (this.itemsSeen.has(itemKey)) {
            console.warn('Duplicate item found, skipping');
            return true;
        }
        this.itemsSeen.add(itemKey);
        return false;
    }

    async addData(scrapedData) {
        if (!this.isDuplicate(scrapedData)) {
            try {
                const jsonLine = JSON.stringify(scrapedData) + '\n';
                await this.writeFile(this.outputFile, jsonLine, 'utf8');
                console.log('Saved item to', this.outputFile);
            } catch (error) {
                console.error('Error saving data:', error);
            }
        }
    }
}

/**
 * Helper to remove HTML tags from a string
 */
function stripHTML(html) {
    if (!html) return "";
    return html.replace(/<[^>]*>/g, ' ').trim();
}

/**
 * Helper to detect currency from text
 */
function detectCurrency(priceText) {
    const text = (priceText || "").toUpperCase();
    const currencyMap = {
        "USD": "USD", "US$": "USD", "US $": "USD", "$": "USD",
        "EUR": "EUR", "€": "EUR",
        "GBP": "GBP", "£": "GBP", "GB£": "GBP",
        "JPY": "JPY", "¥": "JPY", "JP¥": "JPY",
        "CAD": "CAD", "CA$": "CAD", "C$": "CAD",
        "AUD": "AUD", "AU$": "AUD", "A$": "AUD",
        "CNY": "CNY", "CN¥": "CNY", "RMB": "CNY",
        "CHF": "CHF", "FR.": "CHF",
        "SEK": "SEK", "KR": "SEK",
        "NZD": "NZD", "NZ$": "NZD",
    };
    for (const [code, currency] of Object.entries(currencyMap)) {
        if (text.includes(code)) return currency;
    }
    return "USD";
}

/**
 * Helper to parse numeric price from string
 */
function parseNumericPrice(priceText) {
    if (!priceText) return 0;
    const match = priceText.match(/[\d,]+\.?\d*/);
    if (match) {
        const clean = match[0].replace(/,/g, '');
        const val = parseFloat(clean);
        return isNaN(val) ? 0 : val;
    }
    return 0;
}

/**
 * Helper to make absolute URL
 */
function makeAbsoluteURL(urlStr) {
    if (!urlStr) return "";
    if (urlStr.startsWith("http://") || urlStr.startsWith("https://")) return urlStr;
    if (urlStr.startsWith("//")) return "https:" + urlStr;
    const domain = "https://stockx.com";
    if (urlStr.startsWith("/")) return domain + urlStr;
    return domain + "/" + urlStr;
}

/**
 * Extract structured data from HTML using Cheerio
 * @param {Object} $ - Cheerio instance
 * @param {string} url - Source URL
 * @returns {Object|null} - Extracted data or null
 */
function extractData($, url) {
    try {
        let nextData = null;
        const nextDataScript = $('script#__NEXT_DATA__').first().html();
        if (nextDataScript) {
            try {
                nextData = JSON.parse(nextDataScript);
            } catch (e) {
                console.error("Error parsing NEXT_DATA JSON");
            }
        }

        const products = [];
        const productMap = {};
        const globalDescription = $('meta[name="description"]').attr('content') || "";

        // 1. Extract base data from JSON
        if (nextData && nextData.props && nextData.props.pageProps && nextData.props.pageProps.results) {
            const edges = nextData.props.pageProps.results.edges || [];
            edges.forEach(edge => {
                const node = edge.node;
                if (!node) return;

                const p = {};
                const name = node.title || node.name || "";
                p.name = name;
                p.productId = node.id;
                p.brand = node.brand;
                p.category = "sneakers";
                p.availability = "in_stock";
                p.badges = [];
                p.description = name + " brings back a classic look. " + globalDescription;
                
                const keyFeatures = ["Condition: New"];
                const bracketMatches = name.match(/\((.*?)\)/g);
                if (bracketMatches) {
                    bracketMatches.forEach(m => {
                        const content = m.substring(1, m.length - 1);
                        keyFeatures.push("Model: " + content);
                    });
                }
                p.keyFeatures = keyFeatures;

                const slug = (node.urlKey || "").replace(/^\/+|\/+$/g, '');
                p.url = makeAbsoluteURL("/" + slug);

                let priceVal = 0;
                if (node.market && node.market.state && node.market.state.lowestAsk) {
                    const ask = node.market.state.lowestAsk;
                    if (typeof ask.amount === 'number') {
                        priceVal = ask.amount;
                    } else if (typeof ask.amount === 'string') {
                        priceVal = parseNumericPrice(ask.amount);
                    }
                }
                p.price = priceVal;
                p.currency = "USD";
                p.images = [];

                productMap[slug] = products.length;
                products.push(p);
            });
        }

        // 2. Enrich with DOM data
        $("[data-testid='ProductTile'], [data-testid='VariantTile']").each((i, el) => {
            const s = $(el);
            const href = s.find("a").first().attr("href") || "";
            if (!href) return;

            const cleanPath = href.split("?")[0];
            const slug = cleanPath.replace(/^\/+|\/+$/g, '');

            const img = s.find("img").first();
            const src = img.attr("src") || "";
            const alt = img.attr("alt") || "";

            const priceText = s.find("[data-testid='product-tile-lowest-ask-amount']").first().text();
            const curr = detectCurrency(priceText);

            const badges = [];
            if (s.text().includes("Xpress Ship")) {
                badges.push({ "label": "Xpress Ship", "type": "new" });
            }

            if (productMap[slug] !== undefined) {
                const idx = productMap[slug];
                if (src !== "" && products[idx].images.length === 0) {
                    products[idx].images = [{ "url": src, "altText": alt }];
                }
                products[idx].badges = badges;
                products[idx].currency = curr;
            } else {
                const name = s.find("[data-testid='product-tile-title']").first().text();
                const p = {
                    name: name,
                    price: parseNumericPrice(priceText),
                    currency: curr,
                    url: makeAbsoluteURL(cleanPath),
                    availability: "in_stock",
                    productId: slug,
                    brand: "",
                    category: "sneakers",
                    description: name + " " + globalDescription,
                    keyFeatures: ["Condition: New"],
                    badges: badges,
                    images: src !== "" ? [{ "url": src, "altText": alt }] : []
                };
                products.push(p);
            }
        });

        // 3. Fallback logic
        if (products.length === 0) {
            $("a[href*='/']").each((i, el) => {
                const s = $(el);
                const titleEl = s.find("p, span, div").filter((i, sel) => {
                    return ($(sel).attr("data-testid") || "").includes("title");
                }).first();

                const title = titleEl.text();
                if (title !== "") {
                    products.push({
                        name: title,
                        url: makeAbsoluteURL(s.attr("href")),
                        price: parseNumericPrice(s.text()),
                        currency: detectCurrency(s.text()),
                        images: [],
                        keyFeatures: []
                    });
                }
            });
        }

        // Parent object construction
        const outputData = {
            products: products,
            aggregateRating: null,
            availability: "in_stock",
            brand: products.length > 0 ? (products[0].brand || "") : "",
            category: "sneakers",
            currency: "USD",
            description: stripHTML(globalDescription),
            features: [],
            images: [],
            name: products.length > 0 ? products[0].name : "",
            preDiscountPrice: null,
            price: products.length > 0 ? products[0].price : 0,
            productId: products.length > 0 ? products[0].productId : "",
            reviews: [],
            seller: null,
            serialNumbers: [],
            specifications: [],
            url: products.length > 0 ? products[0].url : url,
            videos: [],
            timestamp: new Date().toISOString()
        };

        // Top-level currency detection
        const topPriceText = $("[data-testid='product-tile-lowest-ask-amount']").first().text();
        if (topPriceText) outputData.currency = detectCurrency(topPriceText);

        // Top-level image extraction
        const firstImg = $("img[alt]").first();
        if (firstImg.length > 0) {
            const src = firstImg.attr("src");
            const alt = firstImg.attr("alt");
            if (src) outputData.images = [{ "url": src, "altText": alt }];
        }

        return outputData;
    } catch (error) {
        console.error('Error extracting data from', url, ':', error);
        return null;
    }
}

/**
 * Scrape a single page with retry logic using Puppeteer with stealth
 * @param {string} url - URL to scrape
 * @param {DataPipeline} pipeline - Data pipeline instance
 * @param {Object} browser - Puppeteer browser instance
 * @param {number} retries - Number of retries
 */
async function scrapePage(url, pipeline, browser, retries = CONFIG.maxRetries) {
    let success = false;
    let attempts = 0;

    while (attempts <= retries && !success) {
        let page = null;
        
        try {
            page = await browser.newPage();
            
            // Set viewport
            await page.setViewport({ width: 1920, height: 1080 });
            
            // Set user agent
            await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36');
            
            // Block unnecessary resources for performance optimization
            await page.setRequestInterception(true);
            page.on('request', (request) => {
                const resourceType = request.resourceType();
                if (['image', 'media', 'font', 'stylesheet'].includes(resourceType)) {
                    request.abort();
                } else {
                    request.continue();
                }
            });
            
            // Authenticate with proxy
            await page.authenticate({
                username: PROXY_USERNAME,
                password: PROXY_PASSWORD
            });
            
            // Navigate with optimized wait strategy
            await page.goto(url, { 
                waitUntil: 'domcontentloaded',
                timeout: CONFIG.timeout 
            });
            
            // Wait for potential dynamic lists to render
            try {
                await page.waitForSelector('[data-testid="ProductTile"], [data-testid="product-tile-title"]', { timeout: 10000 });
            } catch (e) {
                // Ignore timeout if selectors don't appear (might be JSON only)
            }
            
            const bodyHTML = await page.evaluate(() => document.body.innerHTML);
            const $ = cheerio.load(bodyHTML);
            
            const scrapedData = extractData($, url);
            
            if (scrapedData) {
                await pipeline.addData(scrapedData);
                success = true;
                console.log('Successfully scraped:', url);
            } else {
                console.warn('No data extracted from:', url);
            }
        } catch (error) {
            console.error('Exception scraping', url, ':', error.message);
            
            if (attempts < retries) {
                const delay = Math.pow(2, attempts) * 1000;
                console.log('Retrying in', delay, 'ms...');
                await new Promise(resolve => setTimeout(resolve, delay));
            }
        } finally {
            if (page) await page.close();
            attempts++;
        }
    }

    if (!success) {
        console.error('Failed to scrape', url, 'after', retries, 'retries');
    }
}

/**
 * Scrape multiple URLs concurrently with controlled concurrency
 * @param {string[]} urls - Array of URLs to scrape
 */
async function concurrentScraping(urls) {
    const pipeline = new DataPipeline(CONFIG.outputFile);
    
    // Launch browser with performance optimizations
    const browser = await puppeteer.launch({
        headless: 'new',
        ignoreHTTPSErrors: true,
        args: [
            `--proxy-server=http://${PROXY_SERVER}:${PROXY_PORT}`,
            '--no-sandbox',
            '--disable-setuid-sandbox',
            '--disable-dev-shm-usage',
            '--disable-accelerated-2d-canvas',
            '--no-first-run',
            '--no-zygote',
            '--disable-gpu',
            '--disable-web-security'
        ]
    });

    try {
        // Process URLs in batches to control concurrency
        for (let i = 0; i < urls.length; i += CONFIG.maxConcurrency) {
            const batch = urls.slice(i, i + CONFIG.maxConcurrency);
            const promises = batch.map(url => scrapePage(url, pipeline, browser, CONFIG.maxRetries));
            
            try {
                await Promise.all(promises);
                console.log('Completed batch', Math.floor(i / CONFIG.maxConcurrency) + 1, 'of', Math.ceil(urls.length / CONFIG.maxConcurrency));
            } catch (error) {
                console.error('Error in batch processing:', error);
            }
        }
    } finally {
        await browser.close();
    }
}

/**
 * Main execution function
 */
async function main() {
    const urls = [
        'https://stockx.com/search?s=kids+shoes',
    ];

    console.log('Starting concurrent scraping with NodeJS Puppeteer-Extra + Stealth...');
    console.log('URLs to scrape:', urls.length);
    console.log('Max concurrency:', CONFIG.maxConcurrency);
    console.log('Output file:', CONFIG.outputFile);

    try {
        await concurrentScraping(urls);
        console.log('Scraping completed successfully!');
    } catch (error) {
        console.error('Scraping failed:', error);
        process.exit(1);
    }
}

// Run the scraper if this file is executed directly
if (require.main === module) {
    main().catch(console.error);
}

module.exports = { extractData, scrapePage, concurrentScraping, DataPipeline };